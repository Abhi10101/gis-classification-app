# ============================================================
# app.py ‚Äî FINAL STABLE VERSION
# ============================================================

import streamlit as st

# ------------------------------------------------------------
# PAGE CONFIG ‚Äî MUST BE FIRST STREAMLIT CALL
# ------------------------------------------------------------
st.set_page_config(
    page_title="GIS Image Classification | Abhinandan Sood",
    layout="wide"
)

# ------------------------------------------------------------
# STANDARD LIBS
# ------------------------------------------------------------
from pathlib import Path
import json
import zipfile
import io
import gc
import yaml
import atexit

# ------------------------------------------------------------
# INTERNAL MODULES (SAFE AFTER PAGE CONFIG)
# ------------------------------------------------------------
import ui_1_main
import ui_2_docs

from dataset_builder import build_dataset
from feature_engineering import prepare_features
from train_rf import train_random_forest
from train_xgb import train_xgboost
from train_lr import train_logistic_regression
from inference_core import run_inference, set_progress_callback
from ndvi_rules import apply_ndvi_rules
from colorize import colorize_class_map

from session_manager import SessionManager
from cleanup import safe_cleanup
from run_tracker import RunTracker
from mailer import send_csv_email

try:
    from validators import validate_inputs
except Exception:
    validate_inputs = None

try:
    from logger import log_event, init_logger
except Exception:
    def log_event(msg, level="INFO"):
        print(f"[{level}] {msg}")

    def init_logger(_):
        pass

# ------------------------------------------------------------
# HARD LIMITS (SAFETY)
# ------------------------------------------------------------
MAX_RASTER_MB = 1500
MAX_CLASS_ZIPS = 10
MAX_ZIP_MB = 50


# ------------------------------------------------------------
# CONFIG
# ------------------------------------------------------------
def load_config() -> dict:
    cfg = Path("config.yaml")
    if not cfg.exists():
        return {}
    with open(cfg, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def validate_email_config(cfg: dict):
    for k in ("sender", "smtp_server", "smtp_port", "app_password"):
        if not cfg.get(k):
            raise ValueError(f"Missing email config key: {k}")


# ------------------------------------------------------------
# MAIN APP
# ------------------------------------------------------------
def main():

    # ---------------- SESSION STATE INIT (SAFE) ----------------
    defaults = {
        "session": None,
        "tracker": None,
        "models_trained": False,
        "inference_done": False,
        "cleanup_done": False,
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

    # ---------------- FAILSAFE CLEANUP ----------------
    def _final_cleanup():
        sess = st.session_state.get("session")
        if sess and not st.session_state.get("cleanup_done"):
            try:
                sess.cleanup(force=True)
            except Exception:
                pass

    atexit.register(_final_cleanup)

    # ---------------- LOAD CONFIG ----------------
    config = load_config()
    inference_cfg = config.get("inference", {})
    ensemble_cfg = config.get("ensemble", {})
    ndvi_cfg = config.get("ndvi_rules", {})
    email_cfg = config.get("email", {})

    tile_size = int(inference_cfg.get("tile_size", 512))
    ensemble_weights = ensemble_cfg.get("weights")
    ndvi_conf_threshold = ndvi_cfg.get("confidence_threshold")

    # ---------------- UI ----------------
    tab_home, tab_docs = st.tabs(["üè† Home", "üìò Documentation"])

    # =========================================================
    # HOME TAB
    # =========================================================
    with tab_home:

        inputs = ui_1_main.render()

        st.divider()
        st.subheader("üß† Model Training")

        # ---------------- TRAIN ----------------
        if st.button("üöÄ Train Models"):

            stack_file = inputs.get("stack_file")
            ndvi_file = inputs.get("ndvi_file")
            classes = inputs.get("classes", [])

            if not stack_file or not ndvi_file:
                st.error("Stack & NDVI rasters are required")
                st.stop()

            if stack_file.size / 1e6 > MAX_RASTER_MB:
                st.error("Stack raster too large")
                st.stop()

            if ndvi_file.size / 1e6 > MAX_RASTER_MB:
                st.error("NDVI raster too large")
                st.stop()

            if len(classes) > MAX_CLASS_ZIPS:
                st.error("Too many class shapefiles")
                st.stop()

            if validate_inputs:
                ok, msg = validate_inputs(inputs)
                if not ok:
                    st.error(msg)
                    st.stop()

            session = SessionManager()
            out_dir = session.create()
            init_logger(out_dir)

            tracker = RunTracker(session_id=out_dir.name)
            tracker.start()

            st.session_state.update({
                "session": session,
                "tracker": tracker,
                "models_trained": False,
                "inference_done": False,
                "cleanup_done": False,
            })

            try:
                with st.status("Training models...", expanded=True):
                    progress = st.progress(0)

                    stack_path = session.path("stack.tif")
                    ndvi_path = session.path("ndvi.tif")
                    stack_path.write_bytes(stack_file.read())
                    ndvi_path.write_bytes(ndvi_file.read())

                    shapefile_info = []
                    color_map = {0: [165, 42, 42]}
                    cid = 1

                    for cls in classes:
                        zp = session.path(f"class_{cid}.zip")
                        zp.write_bytes(cls["zip"].read())
                        shapefile_info.append({
                            "zip_path": str(zp),
                            "label": cls["label"],
                            "class_id": cid
                        })
                        hex_c = cls["color"].lstrip("#")
                        color_map[cid] = [int(hex_c[i:i+2], 16) for i in (0, 2, 4)]
                        cid += 1

                    with open(session.path("class_color_map.json"), "w") as f:
                        json.dump(color_map, f, indent=2)

                    build_dataset(str(stack_path), str(ndvi_path), shapefile_info, str(out_dir))
                    progress.progress(30)

                    prepare_features(
                        str(session.path("X.npy")),
                        str(session.path("y.npy")),
                        str(out_dir)
                    )
                    progress.progress(50)

                    train_random_forest(
                        str(session.path("X_clean.npy")),
                        str(session.path("y_clean.npy")),
                        str(out_dir)
                    )
                    progress.progress(70)

                    train_xgboost(
                        str(session.path("X_clean.npy")),
                        str(session.path("y_clean.npy")),
                        str(out_dir)
                    )
                    progress.progress(85)

                    train_logistic_regression(
                        str(session.path("X_clean.npy")),
                        str(session.path("y_clean.npy")),
                        str(out_dir)
                    )
                    progress.progress(100)

                st.session_state["models_trained"] = True
                st.success("Training completed")

            except Exception as e:
                log_event(f"Training failed: {e}", "ERROR")
                session.cleanup(force=True)
                st.error("Training failed")
                st.stop()

            finally:
                gc.collect()

        # ---------------- INFERENCE ----------------
        st.divider()
        st.subheader("üõ∞Ô∏è Inference")

        if st.button("‚ñ∂Ô∏è Run Inference", disabled=not st.session_state["models_trained"]):

            session = st.session_state["session"]

            try:
                with st.status("Running inference...", expanded=True):
                    progress = st.progress(0)
                    set_progress_callback(lambda p, m: progress.progress(p, m))

                    run_inference(
                        stack_path=str(session.path("stack.tif")),
                        ndvi_path=str(session.path("ndvi.tif")),
                        model_dir=str(session.path()),
                        out_dir=str(session.path()),
                        tile_size=tile_size,
                        ensemble_weights=ensemble_weights
                    )

                    apply_ndvi_rules(
                        str(session.path("predicted_class.tif")),
                        str(session.path("prediction_confidence.tif")),
                        str(session.path("ndvi.tif")),
                        str(session.path("final_class.tif")),
                        ndvi_conf_threshold
                    )

                    colorize_class_map(
                        str(session.path("final_class.tif")),
                        str(session.path("class_color_map.json")),
                        str(session.path("final_class_color.tif"))
                    )

                st.session_state["inference_done"] = True
                st.success("Inference completed")

            finally:
                set_progress_callback(None)
                gc.collect()

        # ---------------- DOWNLOAD & CLEANUP ----------------
        if st.session_state["inference_done"]:

            session = st.session_state["session"]
            tracker = st.session_state["tracker"]

            zip_buf = io.BytesIO()
            with zipfile.ZipFile(zip_buf, "w") as zf:
                for f in (
                    "final_class.tif",
                    "final_class_color.tif",
                    "prediction_confidence.tif",
                    "class_color_map.json",
                ):
                    zf.write(session.path(f), arcname=f)

            zip_buf.seek(0)

            if st.download_button("üì¶ Download Results", zip_buf.getvalue(),
                                  file_name="gis_outputs.zip"):

                try:
                    validate_email_config(email_cfg)
                    csv_path = tracker.export_csv(session.path("run_report.csv"))

                    send_csv_email(
                        csv_path=csv_path,
                        sender_email=email_cfg["sender"],
                        receiver_email=email_cfg.get("receiver", email_cfg["sender"]),
                        smtp_server=email_cfg["smtp_server"],
                        smtp_port=email_cfg["smtp_port"],
                        app_password=email_cfg["app_password"]
                    )
                finally:
                    session.cleanup(force=True)
                    st.session_state["cleanup_done"] = True
                    st.success("Delivered & cleaned")

    # =========================================================
    # DOCS TAB
    # =========================================================
    with tab_docs:
        ui_2_docs.render()


if __name__ == "__main__":
    main()
